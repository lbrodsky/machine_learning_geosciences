{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5f2f589e-d61a-4739-91ab-380a442a36cb",
   "metadata": {},
   "source": [
    "# ___\n",
    "\n",
    "# [ Machine Learning in Geosciences ]\n",
    "\n",
    "**Department of Applied Geoinformatics and Carthography, Charles University** \n",
    "\n",
    "*Lukas Brodsky lukas.brodsky@natur.cuni.cz*\n",
    "    \n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dac454b5-5652-4ef7-9315-2d359318bf52",
   "metadata": {},
   "source": [
    "#  Essential Python Data Science Techniques in **NumPy, Pandas and Matplotlib**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f4df642-1f31-4106-9169-ff09fa737797",
   "metadata": {},
   "source": [
    "# 1: Introduction & Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90a94454-1953-48fe-bc18-df3d5923bd48",
   "metadata": {},
   "source": [
    "## End-to-End Data Processing: Glacial Valley Topography\n",
    "\n",
    "\n",
    "In this lab, we will simulate, clean, and visualize the cross-sectional topographic profile of a U-shaped glacial valley. Real-world elevation data (e.g., from drone LiDAR) is often noisy and contains missing values. We will process this data using the fundamental data science triad: **NumPy, Pandas, and Matplotlib**.\n",
    "\n",
    "Learning Objectives:\n",
    "\n",
    "    1. Formulate non-linear spatial data using NumPy and Linear Algebra.\n",
    "\n",
    "    2. Manage tabular data and impute missing values using Pandas.\n",
    "\n",
    "    3. Create publication-ready geoscience figures using Matplotlib."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf18824e-bfc6-4a99-b239-ad8f88746cee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the required data science libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set a random seed so all students get the exact same \"random\" noise\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a19e689a-651e-40b1-b51b-ebd3b8212a77",
   "metadata": {},
   "source": [
    "# 2: Simulating the Valley using Linear Algebra"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0bf5072-6238-477c-a59b-fedd845b18a5",
   "metadata": {},
   "source": [
    "Data Simulation (NumPy & Linear Algebra)\n",
    "\n",
    "A U-shaped glacial valley can be approximated by a **second-degree polynomial** (parabola):\n",
    "$$ y = ax^2 + bx + c $$\n",
    "\n",
    "Where:\n",
    "* **$y$** is the elevation.\n",
    "* **$x$** is the distance across the valley.\n",
    "* **$a$** controls the steepness of the valley walls.\n",
    "* **$b$** controls the horizontal shift (symmetry).\n",
    "* **$c$** is the base elevation of the valley floor.\n",
    "\n",
    "Instead of calculating this point-by-point, we can use **Linear Algebra** to calculate the entire valley profile at once. We will build a **Design Matrix A** containing our variables, and a **Weight Vector W** containing our coefficients. The true elevation is the **dot product of A and W**.\n",
    "\n",
    "    X: Distance across the valley (meters)\n",
    "\n",
    "    W: Vector of coefficients [a,b,c]\n",
    "\n",
    "$$ Y_{true} = A \\cdot W $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6293d342-4794-4691-807a-7f4c97fe3d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Generate the spatial domain: 500 points from -1000m to 1000m\n",
    "# Use NumPy method linspace()\n",
    "# returns evenly spaced numbers based on a specified interval. \n",
    "# The interval by default includes the starting value and ending value.\n",
    "# X = np.linspace()\n",
    "pass "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e57291e-708b-4874-98fb-4ff06e35c246",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore NumPy method linspace() \n",
    "pass "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31aea74c-18dd-4309-af93-d197a12a4b71",
   "metadata": {},
   "source": [
    "First, we construct the **Design Matrix** ($A$). For $n$ spatial points across the valley, $A$ is an $n \\times 3$ matrix where the columns represent the polynomial features ($x^2$, $x$, and a constant $1$ for the intercept):\n",
    "\n",
    "$$ A = \\begin{bmatrix} \n",
    "x_1^2 & x_1 & 1 \\\\ \n",
    "x_2^2 & x_2 & 1 \\\\ \n",
    "\\vdots & \\vdots & \\vdots \\\\ \n",
    "x_n^2 & x_n & 1 \n",
    "\\end{bmatrix} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "265f5df7-81d1-4f0a-8f2c-837cf85132a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Linear Algebra Setup: Build the Design Matrix (N x 3)\n",
    "# Columns: [X^2, X, 1] (The '1' represents the intercept/base elevation)\n",
    "# Use NumPy column_stack() and ones_like()\n",
    "# A = np.column_stack(()))\n",
    "pass "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25bb4b24-9a96-46c4-9fc3-df5fc9370a1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore NumPy method column_stack()\n",
    "pass "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fcb9d27-4620-4b6f-aace-e47d24cc21e1",
   "metadata": {},
   "source": [
    "Next, we define our **Weight Vector** ($W$), which contains our geologic coefficients $[a, b, c]$. It is a $3 \\times 1$ column vector:\n",
    "\n",
    "$$ W = \\begin{bmatrix} a \\\\ b \\\\ c \\end{bmatrix} $$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e761a97-4abf-45b1-9f1d-d5774dd54363",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Define the Weight Vector (coefficients for a U-shaped valley)\n",
    "# a = 0.0005 (steepness), b = 0 (symmetry), c = 1200 (base elevation in meters)\n",
    "# Use NumPy method array() - a constructuctor from list \n",
    "# W = np.array([...])\n",
    "pass "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9195ad99-b6e0-4101-9cf9-c05155a96b2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore NumPy method array() \n",
    "pass "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c6928e1-1c8e-4ae3-ac36-77c1c13d2ba8",
   "metadata": {},
   "source": [
    "By taking the dot product of $A$ and $W$, we get the $n \\times 1$ vector of our true elevations ($Y_{true}$):\n",
    "\n",
    "$$ Y_{true} = \\begin{bmatrix} \n",
    "x_1^2 & x_1 & 1 \\\\ \n",
    "x_2^2 & x_2 & 1 \\\\ \n",
    "\\vdots & \\vdots & \\vdots \\\\ \n",
    "x_n^2 & x_n & 1 \n",
    "\\end{bmatrix} \\begin{bmatrix} a \\\\ b \\\\ c \\end{bmatrix} = \\begin{bmatrix} y_1 \\\\ y_2 \\\\ \\vdots \\\\ y_n \\end{bmatrix} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65338d1a-57d0-42b7-a549-0da38b45ac41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Matrix Multiplication to get True Elevation (Y_true)\n",
    "# Calculate Y_true as dot product of A and W. Use NumPy np.dot()\n",
    "# Y_true = np.dot(..)\n",
    "pass "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1727021-e8b1-4aa4-afe4-835112070a77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore Numpy method dot()\n",
    "pass "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "008f42d3-87c4-4511-ac57-386a82e24d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Inject Environmental Noise (Simulating rough terrain and sensor noise)\n",
    "# generate noise using NumPy np.random.normal() \n",
    "# loc=0 (Mean), scale=35 (Standard deviation - spread), size=X.shape \n",
    "# noise = np.random.normal()\n",
    "pass \n",
    "# add the noise to the true data to simulate measured data \n",
    "# Y_measured = Y_true + noise\n",
    "pass "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a471358-0091-4f13-a798-44c01b3c9f34",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Shape of Design Matrix A: {A.shape}\")\n",
    "print(f\"Shape of Weight Vector W: {W.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b351ce57-890b-4c86-818c-0100d9b7b14c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore NumPy method random.normal()\n",
    "pass "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e23e95ea-6bb5-4e29-807f-0c94eca2b61f",
   "metadata": {},
   "source": [
    "# 3: Structuring and Cleaning Messy Data\n",
    "\n",
    "**Data Management & Cleaning (Pandas)** \n",
    "\n",
    "Geoscience data is rarely perfect. Sensors fail, water surfaces absorb LiDAR pulses, and errors occur. We will move our raw NumPy arrays into a structured Pandas DataFrame.\n",
    "\n",
    "We will artificially drop 5% of our sensor readings to simulate missing data (NaNs). Then, we will use Pandas to:\n",
    "\n",
    "    1. Interpolate (fill in) the missing gaps.\n",
    "\n",
    "    2. Apply a rolling window mean to smooth out the high-frequency sensor noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c69d0a67-3536-4e4a-9be4-b132e6f3ef0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Create a Pandas DataFrame\n",
    "# Use pandas pd.DataFrame() constructor, pass disctionary with data, keys become the columns  \n",
    "df = pd.DataFrame({\n",
    "    'Distance_m': X,\n",
    "    'True_Elevation_m': Y_true,\n",
    "    'Measured_Elevation_m': Y_measured\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcff655a-0868-40c1-9893-3eaa5aedcb99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore pandas method DataFrame() \n",
    "pass "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b4f4d59-b8c8-417e-8d8d-e6de1532dfa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore DataFrame columns \n",
    "pass "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a15e83e-7c0a-4a56-be75-0d561fef1834",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Simulate Sensor Failure: Randomly replace 5% of measurements with NaN\n",
    "drop_indices = np.random.choice(df.index, size=int(0.05 * len(df)), replace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d772c7d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# explore the indices series\n",
    "pass "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "881c30fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace the data with NaN \n",
    "df.loc[drop_indices, 'Measured_Elevation_m'] = np.nan\n",
    "print(f\"Missing data points before cleaning: {df['Measured_Elevation_m'].isna().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a309dd8a-33c5-43d4-807c-5db8896c097d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore Pandas method random.choice()\n",
    "pass "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e9a2062-806a-4906-9bac-fcec36941ab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore Pandas indexing df.index \n",
    "pass "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2496b9b2-933a-4fcb-83b5-4c1ce32d72f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore Pandas df.loc[] \n",
    "pass "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ecee111-df55-4305-829c-4e64781a79e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Data Imputation: Fill missing values using polynomial interpolation\n",
    "# here the pandas method interpoalte() fill NaN values using polynomial interpolation method.\n",
    "df['Cleaned_Elevation_m'] = df['Measured_Elevation_m'].interpolate(method='polynomial', order=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7494e260",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Missing data points after cleaning: {df['Cleaned_Elevation_m'].isna().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4321e63-0653-4d32-81e9-dd60ad972c2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore Pandas function isnan() and sum() \n",
    "pass "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3d2337e-7d6a-4979-a7e1-e92506029ceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Feature Engineering: Apply a Rolling Window Average to smooth noise\n",
    "# Pandas method rolling() provide rolling window calculations\n",
    "# window=15 means it averages the 15 neighboring spatial points\n",
    "\n",
    "df['Smoothed_Elevation_m'] = df['Cleaned_Elevation_m'].rolling(window=15, center=True).mean()\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "618b4c9e-da74-4e59-931a-019fc2ab4075",
   "metadata": {},
   "source": [
    "# 4. Geoscience Visualization\n",
    "\n",
    "Visual Reporting - **Matplotlib** \n",
    "\n",
    "Data science in the geosciences requires clear, accurately labeled visualizations. We will use Matplotlib's object-oriented API (plt.subplots()) to overlay our raw noisy data, our Pandas-smoothed data, and the underlying mathematical truth.\n",
    "\n",
    "Notice how the Pandas rolling.mean() does a decent job, but struggles near the steep edges of the valley. This visual limitation will perfectly motivate the need for Scikit-Learn Regression models in our next lab!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0213af6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Matplotlib to plot the data \n",
    "\n",
    "# 1.Create a figure and axis (plt.subplots()).\n",
    "\n",
    "# 2. Plot:\n",
    "# - Scatter points (raw LiDAR data)\n",
    "# - Lines (smoothed data and true profile)\n",
    "\n",
    "# 3. Format the plot (title, labels, grid, legend).\n",
    "\n",
    "# 4. Display the final result (plt.show())."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f3edf6b-8461-45d1-a2d0-597a9fca284a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Initialize the Figure and Axes\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "# 2. Plot the raw, noisy LiDAR measurements\n",
    "ax.scatter(df['Distance_m'], df['Measured_Elevation_m'], \n",
    "           color='gray', alpha=0.4, s=15, label='Raw Sensor Data (Noisy)')\n",
    "\n",
    "# 3. Plot the Pandas Smoothed Data\n",
    "ax.plot(df['Distance_m'], df['Smoothed_Elevation_m'], \n",
    "        color='blue', linewidth=2.5, linestyle='--', label='Pandas Rolling Mean')\n",
    "\n",
    "# 4. Plot the Underlying Mathematical Truth\n",
    "ax.plot(df['Distance_m'], df['True_Elevation_m'], \n",
    "        color='red', linewidth=2, label='True Geologic Profile')\n",
    "\n",
    "# 5. Formatting the Plot for a Science Report\n",
    "ax.set_title(\"Cross-Sectional Topographic Profile of a Glacial Valley\", fontsize=16, fontweight='bold')\n",
    "ax.set_xlabel(\"Distance Across Valley [m]\", fontsize=12)\n",
    "ax.set_ylabel(\"Elevation [m.a.s.l.]\", fontsize=12)\n",
    "\n",
    "# Add grid lines for readability\n",
    "ax.grid(True, linestyle=':', alpha=0.7)\n",
    "\n",
    "# Add the legend to identify the layers\n",
    "ax.legend(loc='upper center', fontsize=11)\n",
    "\n",
    "# Render the plot\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d526a88f-2a03-4950-a998-7399b60459b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore Matplotlib elements: \n",
    "# scatter()\n",
    "# plot\n",
    "pass "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
